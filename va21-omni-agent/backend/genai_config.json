{
  "search": {
    "batch": 1,
    "early_exit_attention_mask": false,
    "gqa_num_kv_heads": 8,
    "hidden_size": 3072,
    "intermediate_size": 8192,
    "max_length": 4096,
    "model_type": "phi3",
    "num_attention_heads": 32,
    "num_hidden_layers": 32,
    "num_key_value_heads": 8,
    "vocab_size": 32064
  }
}